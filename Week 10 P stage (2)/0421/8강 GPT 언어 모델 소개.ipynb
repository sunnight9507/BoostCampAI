{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "published-input",
   "metadata": {},
   "source": [
    "### 1. GPT 언어 모델\n",
    "\n",
    "#### 1.1 GPT 모델 소개\n",
    "\n",
    "- BERT : Transformer의 encoder를 사용\n",
    "- GPT : Transformer의 decoder를 사용\n",
    "\n",
    "\n",
    "- 기존의 문장 입력을 context vector로 출력\n",
    "- vector를 linear layer로 분류 task에 적용하기 위해 설계\n",
    "\n",
    "\n",
    "- `자연어 문장 -> 분류` 성능이 아주 좋은 디코더인 GPT\n",
    "- 적은 양의 데이터에서도 높은 분류 성능을 나타냄\n",
    "- But, 지도 학습을 필요로 하고 labeled data가 필수\n",
    "- 특정 task를 위해 fine-tuning된 모델은 다른 task에서 사용 불가능\n",
    "- => **언어**의 특성 상, 지도학습의 목적 함수는 비지도 학습의 목적함수와 같다.\n",
    "    - fine-tuning이 필요 없다.\n",
    "    \n",
    "- Fine-tuning\n",
    "    - pre-trained 모델로 사용자의 task의 맞는 data를 넣어줌으로써 gradient를 업데이트 하는 방식\n",
    "    - 사용자의 task에 맞는 모델이 된다.\n",
    "- Zero-show, One-shot, Few-shot\n",
    "    - No gradient updates\n",
    "    - 힌트의 양에 따라 구분되어진다.\n",
    "    \n",
    "    \n",
    "- GPT2\n",
    "    - Large size + Large training data\n",
    "    - 11GB -> 40GB\n",
    "    - 다음 단어 예측 방식에서 SOTA 성능\n",
    "    - 기계독해, 요약, 번역 등의 자연어 task에서 일반 신경망 수준\n",
    "    \n",
    "\n",
    "- GPT3\n",
    "    - Large size + Large training data\n",
    "    - 40GB -> 570GB\n",
    "    - 전체적인 구조는 GPT2 비슷\n",
    "    \n",
    "    \n",
    "- 한계\n",
    "    - **다음 단어** 혹은 **masked 단어** 예측하는 언어 모델 학습 방식으로 다 해결될까?\n",
    "    - **weight update**가 없다는 것 -> 새로운 지식 학습이 없다.\n",
    "    - **멀티 모달** 정보가 필요 -> GPT는 글로만 세상을 배움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-latter",
   "metadata": {},
   "source": [
    "### 새로 학습한 내용\n",
    "\n",
    "### 시도한 것\n",
    "\n",
    "- 의미 있는(?) best seed 찾기\n",
    "    - 9507이 왜 1등인지...\n",
    "- entity 강조\n",
    "    - 스폐셜 토큰 추가 X\n",
    "    - validation accuracy가 대체로 1% 정도 낮다...\n",
    "    - validation 기준 가장 잘 나온 결과 제출: 77.4\n",
    "    - 기존 80.3에 사용된 3개 결과와 hard voting하니 80.9..?\n",
    "\n",
    "### TODO\n",
    "\n",
    "- data mask 씌우기\n",
    "- tokenize 형태소 단위로 변경"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
