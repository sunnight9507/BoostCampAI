{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-anderson",
   "metadata": {},
   "source": [
    "### 1. Introduction to MRC\n",
    "\n",
    "- **Machine Reading Comprehension (MRC)**\n",
    "    - 주어진 지문(Context)를 이해하고, 주어진 질의 (Query/Question)의 답변을 추론하는 문제\n",
    "\n",
    "\n",
    "- **MRC의 종류**\n",
    "- 1) Extractive Answer Datasets\n",
    "    - 질의(Question)에 대한 답이 항상 주어진 지문(context)의 segment(or span)으로 존재\n",
    "- 2) Descriptive / Narrative Answer Datasets\n",
    "    - 답이 지문 내에서 추출한 span이 아니라, 질의를 보고 생성된 sentence(or free-form)의 형태\n",
    "- 3) Multiple-choice Datasets\n",
    "    - 질의에 대한 답을 여러 개의 answer candidates 중 하나로 고르는 형태\n",
    "\n",
    "\n",
    "- **Challenge in MRC**\n",
    "    - 단어들의 구성이 유사하지는 않지만 동일한 의미의 문장을 이해\n",
    "    - Unanswerable questions\n",
    "        - Question with **No Answer**\n",
    "    - Multi-hop reasoning\n",
    "        - 여러 개의 document에서 질의에 대한 supporting fact를 찾아야지만 답을 찾을 수 있음\n",
    "        \n",
    "\n",
    "- **MRC의 평가방법**\n",
    "- 1) **Exact Match / F1 Score** : For <U>extractive</U> answer and <U>multiple-choice</U> answer datasets\n",
    "    - **Exact Match**\n",
    "        - 예측한 답과 ground-truth이 정확히 일치하는 샘플의 비율\n",
    "        - (Number of correct samples) / (Number of whole samples)\n",
    "    - **F1 Score**\n",
    "        - 예측한 답과 ground-truth 사이의 token overlap을 F1으로 계산\n",
    "- 2) **ROUGE-L / BLEU** : For <U>descriptive</U> answer datasets => Ground-truth과 예측한 답 사이의 overlap을 계산\n",
    "    - **ROUGE-L**\n",
    "        - 예측한 답과 Ground-truth 사이의 overlap recall\n",
    "        - ROUGE-<U>L</U> => LCS (Longest common subsequence 기반)\n",
    "    - **BLEU (Bilingual Evaluation Understudy)**\n",
    "        - 예측한 답과 Ground-truth 사이의 pricision\n",
    "        - BLEU-<U>n</U> => uniform <U>n</U>-gram weight\n",
    "\n",
    "\n",
    "### 2. Unicode & Tokenization\n",
    "\n",
    "- **Unicode란**\n",
    "    - 전 세계의 모든 문자를 일관되게 표현하고 다룰 수 있도록 만들어진 문자셋\n",
    "    - 각 문자마다 숫자 하나에 매핑한다.\n",
    "\n",
    "\n",
    "- **인코딩 & UTF-8**\n",
    "    - **인코딩** : 문자를 컴퓨터에서 저장 및 처리할 수 있게 이진수로 바꾸는 것\n",
    "    - **UTF-8**\n",
    "        - 현재 가장 많이 쓰는 인코딩 방식\n",
    "        - 문자 타입에 따라 다른 길이의 바이트를 할당한다.\n",
    "\n",
    "\n",
    "- **Python에서 Unicode 다루기**\n",
    "    - **ord** : 문자를 유니코드 code point로 변환한다.\n",
    "    - **chr** : Code point를 문자로 변환한다.\n",
    "    \n",
    "\n",
    "- **Unicode와 한국어**\n",
    "    - 한자 다음으로 유니코드에서 많은 코드를 차지하고 있다.\n",
    "    - 완성형, 조합형으로 구분된다.\n",
    "    \n",
    "\n",
    "- **토크나이징**\n",
    "    - 텍스트를 토큰 단위로 나누는 것\n",
    "    - 단위(띄어쓰기 기준), 형태소, subword 등 여러 토큰 기준이 사용된다.\n",
    "- **Subword 토크나이징**\n",
    "    - 자주 쓰이는 글자 조합은 한 단위로 취급하고, 자주 쓰이지 않는 조합은 subword로 쪼갠다.\n",
    "    - **\\#\\#**은 디코딩 (토크나이징의 반대 과정)을 할 때 해당 토큰을 앞 토큰에 띄어쓰기 없이 붙인다는 것을 뜻한다.\n",
    "    \n",
    "\n",
    "- **BPE (Byte-Pair Encoding)**\n",
    "    - 데이터 압축용으로 제안된 알고리즘\n",
    "    - NLP에서 토크나이징용으로 활발하게 사용되고 있다.\n",
    "    - 과정\n",
    "        - 1) 가장 자주 나오는 글자 단위 Bigram (or Byte pair)를 다른 글자로 치환\n",
    "        - 2) 치환된 글자를 저장\n",
    "        - 3) 1~2번을 반복\n",
    "\n",
    "### 3. Looking into the Dataset\n",
    "\n",
    "- **KorQuAD 훑어보기**\n",
    "    - LG CNS가 AI 언어지능 연구를 위해 공개한 질의응답/기계독해 한국어 데이터셋 인공지능이 한국어 질문에 대한 답변을 하도록 필요한 학습 데이터셋"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
