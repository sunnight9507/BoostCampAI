{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-trinidad",
   "metadata": {},
   "source": [
    "### 1. Introduction to Passage Retrieval\n",
    "\n",
    "#### Passage Retrieval\n",
    "- 질문에 맞는 문서를 찾는 것\n",
    "\n",
    "#### Passage Retrieval with MRC\n",
    "- Open-domain Question Answering: 대규모의 문서 중에서 질문에 대한 답을 찾기\n",
    "    - Passage Retrieval과 MRC를 이어서 2-Stage로 만들 수 있음\n",
    "    \n",
    "#### Overview of Passage Retrieval\n",
    "- Query와 Passage를 임베딩한 뒤 유사도로 랭킹을 매기고, 유사도가 가장 높은 Passage를 선택함\n",
    "\n",
    "### 2. Passage Embedding and Sparse Embedding\n",
    "\n",
    "#### Passage Embedding Space\n",
    "- Passage Embedding의 벡터 공간\n",
    "- 벡터화된 Passage를 이용하여 Passage간 유사도 등을 알고리즘으로 계산할 수 있음\n",
    "\n",
    "#### Sparse Embedding 소개\n",
    "- **Bag-of-Words** (BoW)\n",
    "- BoW를 구성하는 방법 => **n-gram**\n",
    "    - unigram (1-gram)\n",
    "    - bigram (2-gram)\n",
    "- Term value를 결정하는 방법\n",
    "    - Term이 documnet에 등장하는지 (binary)\n",
    "    - Term이 몇 번 등장하는지 (term frequency)\n",
    "    \n",
    "#### Sparse Embedding 특징\n",
    "- Dimension of embedding vector = number of terms\n",
    "    - 등장하는 단어가 많아질수록 증가\n",
    "    - N-gram의 n이 커질수록 증가\n",
    "- Term overlap을 정확하게 잡아 내야 할 때 유용\n",
    "- 반면, 의미(semantic)가 비슷하지만 다른 단어인 경우 비교가 불가\n",
    "\n",
    "### 3. TF-IDF\n",
    "\n",
    "####  TF-IDF 소개\n",
    "- Term Frequency (TF) : 단어의 등장빈도\n",
    "- Inverse Document Frequency (IDF) : 단어가 제공하는 정보의 양\n",
    "\n",
    "####  Term Frequency (TF)\n",
    "- 해당 문서 내 단어의 등장 빈도\n",
    "    - Raw count\n",
    "    - Adjusted for doc length: raw count / num words (TF)\n",
    "    - Other variants: binary, log normalization\n",
    "    \n",
    "#### Inverse Document Frequency (IDF)\n",
    "- 단어가 제공하는 정보의 양\n",
    "- $ \\mathrm{IDF}(t) = \\log{\\frac{N}{\\mathrm{DF}(t)}} $\n",
    "    - Document Frequency (DF) : Term t가 등장한 document의 개수\n",
    "    - N : 총 document의 개수\n",
    "    \n",
    "#### Combine TF & IDF\n",
    "- TF-IDF(t, d): TF-IDF for term t in document d\n",
    "    - $ \\mathbf{TF(t, d)} \\times \\mathbf{IDF(t)} $\n",
    "    \n",
    "#### BM25란?\n",
    "\n",
    "- TF-IDF의 개념을 바탕으로, 문서의 길이까지 고려하여 점수를 매김\n",
    "    - TF 값에 한계를 지정해두어 일정한 범위를 유지하도록 함\n",
    "    - 평균적인 문서의 길이보다 더 작은 문서에서 단어가 매칭된 경우 그 문서에 대해 가중치를 부여\n",
    "    - 실제 검색엔진, 추천 시스템 등에서 아직까지도 많이 사용되는 알고리즘\n",
    "\n",
    "\n",
    "$$ Score(D, Q) = \\sum_{term \\in Q} \\mathrm{IDF(term)} \\cdot \\frac{\\mathrm{TFIDF(term, D)} \\cdot (k_1 + 1)}{\\mathrm{TFIDF(term, D)} + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{avgdl})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-shuttle",
   "metadata": {},
   "source": [
    "### 시도한 것\n",
    "\n",
    "- 수지님 json data를 HuggingFace Datasets 형식으로 변경\n",
    "    - MRC에서 적용 가능할 듯?\n",
    "    - Retrieval에서 적용하려면 wikipedia_documents도 변경해야 되는데...\n",
    "    - 1이 커지는데...\n",
    "\n",
    "### 새로 알게된 것\n",
    "\n",
    "- answer에서 ''가 중복된 데이터 존재\n",
    "    - ex) train 15번째 data => \"'초일기'\"\n",
    "\n",
    "### TODO\n",
    "\n",
    "- MRC 실습 코드 내 거 만들기\n",
    "- train code 이해하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
