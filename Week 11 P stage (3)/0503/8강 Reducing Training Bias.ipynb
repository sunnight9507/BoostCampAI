{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-church",
   "metadata": {},
   "source": [
    "### 1. Definition of Bias\n",
    "\n",
    "#### Bias의 종류\n",
    "\n",
    "- Bias in learning\n",
    "    - 학습할 때 과적합을 막거나 사전 지식을 주입하기 위해 특정 형태의 함수를 선호하는 것 (inductive bias)\n",
    "    \n",
    "    \n",
    "- A Biased World\n",
    "    - 현실 세계가 편향되어 있기 때문에 모델에 원치 않는 속성이 학습되는 것 (historical bias)\n",
    "    - 성별과 직업 간 관계 등 표면적인 상관관계 때문에 원치 않는 속성이 학습되는 것 (co-occurrence bias)\n",
    "    \n",
    "    \n",
    "- Bias in Data Generation\n",
    "    - 입력과 출력을 정의한 방식 때문에 생기는 편향 (specification bias)\n",
    "    - 데이터를 샘플링한 방식 때문에 생기는 편향 (sampling bias)\n",
    "    - 어노테이터의 특성 때문에 생기는 편향 (annotator bias)\n",
    "    \n",
    "    \n",
    "#### Gender Bias\n",
    "- 대표적인 bias 예시\n",
    "- 특정 성별과 행동을 연관시켜서 예측 오류가 발생\n",
    "\n",
    "#### Sampling Bias\n",
    "- `리터러시 다이제스트` 여론조사 (1936년)\n",
    "\n",
    "### 2. Bias in Open-domain Question Answering\n",
    "\n",
    "#### Retriver-Reader Pipeline\n",
    "\n",
    "#### Training bias in reader model\n",
    "- 만약 reader 모델이 만약 한정된 데이터셋에서만 학습이 된다면..\n",
    "    - Reader은 항상 정답이 문서 내에 포함된 데이터쌍만(Positive)을 보게 됨\n",
    "\n",
    "#### How to mitigate training bias?\n",
    "- 1) Train negative examples\n",
    "    - 어떻게 (좋은) Negative sample을 만들 수 있을까?\n",
    "    - Corpus내에서 랜덤하게 뽑기\n",
    "    - 좀 더 헷갈리는 negative 샘플들 뽑기\n",
    "- 2) Add no answer bias\n",
    "\n",
    "### 3. Annotation Bias from Datasets\n",
    "\n",
    "#### What is annotation bias?\n",
    "\n",
    "- ODQA 학습 시 기존의 MRC 데이터셋 활용\n",
    "    - 질문은 하는 사람이 답을 알고 있음\n",
    "    \n",
    "#### Effect of annotation bias\n",
    "\n",
    "#### Dealing with annotation bias\n",
    "\n",
    "- Annotation 단계에서 발생할 수 있는 bias를 인지하고, 이를 고려하여 데이터를 모아야 함\n",
    "    - ex) Natural Questions: Supporting evidence가 주어지지 않은, 실제 유저의 qeustion들을 모아서 dataset을 구성\n",
    "    \n",
    "#### Another bias in MRC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-intro",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### 시도한 것\n",
    "\n",
    "- TF-IDF => BM25\n",
    "    - precision@5 기준으로 30% 상승\n",
    "- bert-base-multilingual-cased => monologg/koelectra-base-v3-discriminator\n",
    "- Reader\n",
    "    - inference 단계에서 top k 인 context concat\n",
    "    - 3, 5, 7, 10, 20 중 7이 가장 높은 성능을 보임\n",
    "\n",
    "### 새로 알게된 것\n",
    "\n",
    "### TODO\n",
    "\n",
    "- **Retireval**\n",
    "    - Doc2Vec\n",
    "    - Sentence transformers\n",
    "    - Ensemble\n",
    "    \n",
    "\n",
    "- **Reader**\n",
    "    - Data preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
