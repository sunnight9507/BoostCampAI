{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-adventure",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "> - First-order iterative optimization algorithm for finding a local minimum of a differentiable function.\n",
    "\n",
    "### Important Concepts in Optimization\n",
    "\n",
    "> #### Generalization\n",
    "> - Training error와 Test error 사이의 차이를 의미\n",
    "> - Generalization performance가 좋다는 것은 네트워크의 성능이 Training error와 비슷하게 나올것이라는 의미\n",
    "\n",
    "> #### Underfitting vs. Overfitting\n",
    "> - Overfitting : train data에 잘 작동되지만 test data에 잘 작동하지 않는 네트워크\n",
    "> - Underfitting : train data에도 잘 작동하지 않는 네트워크\n",
    "\n",
    "> #### Cross-validation\n",
    "> - training data를 $k$개로 나눈 다음에 $k-1$개로 학습시키고 나머지 하나는 validation data로 네트워크를 검증한다.\n",
    "\n",
    "> #### Bias and Variance\n",
    "> - <img src=\"../../image/day12_1.png\" width = 300 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-wayne",
   "metadata": {},
   "source": [
    "> - **Bias and Variance Tradeoff**\n",
    "> - $\\mathrm{Given} \\mathcal{D} = \\{(x_i, t_i)\\}_{i=1}^N, \\mathrm{where} t = f(x) + \\epsilon\\ \\mathrm{and}\\ \\epsilon \\thicksim \\mathcal{N}(0, \\sigma^2)$\n",
    "> - **cost**를 minimize한다는  것은 **`bias^2`**, **`variance`**, **`noise`**를 줄이는 것과 동일하다.\n",
    "    - 이때 하나를 줄이면 다른 값의 크기가 커진다.\n",
    "> - $\\mathbb{E} \\begin{bmatrix} (t-\\hat{f})^2 \\end{bmatrix} = \\mathbb{E} \\begin{bmatrix} (t-f+f-\\hat{f})^2 \\end{bmatrix} = \\mathbb{E} \\begin{bmatrix} (f-\\mathbb{E}[\\hat{f}]^2)^2 \\end{bmatrix} + \\mathbb{E} \\begin{bmatrix} (\\mathbb{E}[\\hat{f}]-\\hat{f})^2 \\end{bmatrix} + \\mathbb{E} [\\epsilon]$\n",
    "> - **cost** = **`bias^2`** + **`variance`** + **`noise`**\n",
    "\n",
    "> #### Bootstrapping\n",
    "> - Bootstrapping is any test or metric that uses random sampling with replacement.\n",
    "> - 학습데이터가 고정되어 있을 때 여러 부분집합을 만들어 여러 모델을 생성하는 것\n",
    "\n",
    "> #### Bagging vs. Boosing\n",
    "> - **`Bagging`**(**B**ootstrapping **agg**regat**ing**) \n",
    "> - Boostrapping으로 학습된 여러 모델 사용\n",
    "> - 여러 모델으로부터 나온 값들의 평균 또는 voting으로 결과값 도출\n",
    "> - Ensemble이라고도 불린다.\n",
    "> - **`Boosting`**\n",
    "> - 약한 학습기를 생성 후 오차가 큰 데이터를 바탕으로 다시 모델 생성을 반복\n",
    "> - weak learner를 sequence하게 만들어 하나의 strong learner를 생성하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-seattle",
   "metadata": {},
   "source": [
    "### Gradient Descent Methods\n",
    "\n",
    "> - **Stochastic gradient descent**\n",
    "> - 전체 데이터 중 **하나씩**만 계산하는 방식\n",
    "\n",
    "> - **Mini-batch gradient descent**\n",
    "> - 데이터의 일부 **batch size만큼**만 계산하는 방식\n",
    "\n",
    "> - **Batch gradient descent**\n",
    "> - **전체 데이터를 이용**해 계산하는 방식\n",
    "\n",
    "> #### Gradient Descent\n",
    "> - $W_{t+1} \\leftarrow W_t - \\eta g_t$\n",
    "> - $W$ : Weight\n",
    "> - $\\eta$ : Learning rate\n",
    "> - 적절한 Learning rate를 찾는게 핵심\n",
    "\n",
    "> #### Momentum\n",
    "> - $a_{t+1} \\leftarrow \\beta a_t + g_t$\n",
    "> - $W_{t+1} \\leftarrow W_t - \\eta a_{t+1}$\n",
    "> - $\\beta$ : momentum\n",
    "> - $a_{t+1}$ : accumulation\n",
    "\n",
    "> #### Nesterov Accelerated Gradient (NAG)\n",
    "> - $a_{t+1} \\leftarrow \\beta a_t + \\nabla \\mathcal{L}(W_t - \\eta \\beta a_t)$\n",
    "> - $W_{t+1} \\leftarrow W_t - \\eta a_{t+1}$\n",
    "> - $\\nabla \\mathcal{L}(W_t - \\eta \\beta a_t)$ : Lookahead gradient\n",
    "\n",
    "> #### Adagrad\n",
    "> - $W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} g_t$\n",
    "> - $G_t$ : Sum of gradient squares\n",
    "> - 뒤로 갈수록 학습이 점점 멈춰지는 문제\n",
    "\n",
    "> #### Adadelta\n",
    "> - Adagrad의 문제점을 개선한 optimizer\n",
    "> - learning rate가 없다.\n",
    "\n",
    "> #### RMSprop\n",
    "> - $G_t = \\gamma G_{t-1} + (1-\\gamma) g_t^2$\n",
    "> - $W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} g_t$\n",
    "> - $G_t$ : EMA of gradient squares\n",
    "> - $\\eta$ : step size\n",
    "\n",
    "> #### Adam\n",
    "> - $m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$\n",
    "> - $v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$\n",
    "> - $W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}} \\frac{\\sqrt{1-\\beta_2^t}}{1-\\beta_1^t} m_t$\n",
    "> - $m_t$ : Momentum\n",
    "> - $v_t$ : EMA of gradient squares\n",
    "\n",
    "### Regularization\n",
    "\n",
    "> #### Early Stopping\n",
    "> - Validation error의 값이 어느 시점에서 커지기 시작할 때 Stop\n",
    "\n",
    "> #### Parameter Norm Penalty\n",
    "> - $\\mathrm{total cost} = \\mathrm{loss}(\\mathcal{D}; W) + \\frac{\\alpha}{2} \\Vert W \\Vert_2^2$\n",
    "\n",
    "> #### Data Augmentation\n",
    "> - 주어진 data를 활용해 data 수를 늘리는 방법\n",
    "\n",
    "> #### Noise Robustness\n",
    "> - 입력 data, weights에 noise를 추가하는 방법\n",
    "\n",
    "> #### Label Smoothing\n",
    "> - Data 두 개를 뽑아서 mix 해주는 방법\n",
    "> - Decision boundary를 부드럽게 만들어주는 효과\n",
    "> - Mixup, CutMix\n",
    "\n",
    "> #### Dropout\n",
    "> - weight의 일부를 0으로 바꿔주는 방법\n",
    "\n",
    "> #### Batch Normalization\n",
    "> - 각 layer에 들어갈 값들을 정규화 시켜주는 방법\n",
    "> - 정규화 종류 : Batch, Layer, Instance, Group Norm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
