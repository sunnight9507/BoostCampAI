{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-operations",
   "metadata": {},
   "source": [
    "## 1. 군집 구조와 군집 탐색 문제\n",
    "\n",
    "### 1.1 군집의 정의\n",
    "\n",
    "> - **군집(Community)이란 다음 조건들을 만족하는 정점들의 집합이다.**\n",
    "    - (1) 집합에 속하는 정점 사이에는 많은 간선이 존재한다.\n",
    "    - (2) 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재한다.\n",
    "     - 수학적으로 엄밀한 정의는 아닙니다\n",
    "\n",
    "### 1.2 실제 그래프에서의 군집들\n",
    "\n",
    "> - **온라인 소셜 네트워크의 군집**들은 **사회적 무리(Social Circle)**를 의미하는 경우가 많다.\n",
    "> - 온라인 소셜 네트워크의 군집들이 **부정 행위와 관련된 경우**도 많다.\n",
    "> - **조직 내의 분란**이 소셜 네트워크 상의 군집으로 표현된 경우도 있다.\n",
    "> - 키워드 – 광고주 그래프에서는 동일한 주제의 키워드들이 군집을 형성한다.\n",
    "> - 뉴런간 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미한다.\n",
    "\n",
    "### 1.3 군집 탐색 문제\n",
    "\n",
    "> - **그래프를 여러 군집으로 나누는 문제를 `군집 탐색(Community Detection)문제`**라고 한다.\n",
    "> - 보통은 각 정점이 한 개의 군집에 속하도록 군집을 나눈다.\n",
    "> - 비지도 기계학습 문제인 클러스터링(Clustering)과 상당히 유사하다.\n",
    "> - 먼저 **성공적인 군집 탐색**부터 정의하자.\n",
    "\n",
    "## 2. 군집 구조의 통계적 유의성과 군집성\n",
    "\n",
    "### 2.1 비교 대상: 배치 모형\n",
    "\n",
    "> - **성공적인 군집 탐색을 정의하기 위해 먼저 `배치 모형`(Configuration Model)을 소개한다.**\n",
    "> - 그래프에 대한 배치 모형은 다음과 같다.\n",
    "    - 1) 각 정점의 연결성(Degree)을 보존한 상태에서\n",
    "    - 2) 간선들을 무작위로 재배치하여서 얻은 그래프\n",
    "> - 배치 모형에서 임의의 두 정점 $i$와 $j$사이에 간선이 존재할 확률은 두 정점의 연결성에 비례한다.\n",
    "\n",
    "\n",
    "### 2.2 군집성의 정의\n",
    "\n",
    "> - **군집 탐색의 성공 여부를 판단하기 위해서, `군집성`(Modularity)이 사용된다.**\n",
    "    - 그래프와 군집들의 집합 S가 주어졌다고 가정하자.\n",
    "    - 각 군집 $s \\in S$이 군집의 성질을 잘 만족하는 지를 살펴보기 위해, 군집 내부의 간선의 수를 그래프와 배치 모형에서 비교한다.\n",
    "> - 구체적으로, **군집성**은 다음 수식으로 계산됩니다 \n",
    "> - $\\frac{1}{2|E|} \\sum_{s \\in S}$ (**그래프**에서 군집 $s$ 내부 간선의 수 $-$ **배치 모형**에서 군집 $s$ 내부 간선의 수의 기댓값)\n",
    "> - 즉, 배치 모형과 비교했을 때, 그래프에서 군집 내부 간선의 수가 월등히 많을 수록 성공한 군집 탐색이다.\n",
    "\n",
    "> - **`군집성`은 무작위로 연결된 배치 모형과의 비교를 통해 통계적 유의성을 판단한다.**\n",
    "> - 군집성은 항상 $–1$과 $+1$ 사이의 값을 갖는다.\n",
    "> - 보통 군집성이 $0.3 \\sim 0.7$ 정도의 값을 가질 때, 그래프에 존재하는 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있다.\n",
    "\n",
    "## 3. 군집 탐색 알고리즘\n",
    "\n",
    "### 3.1 Girvan-Newman 알고리즘\n",
    "\n",
    "> - **`Girvan-Newman 알고리즘`**은 대표적인 **하향식(Top-Down) 군집 탐색 알고리즘**이다.\n",
    "> - Girvan-Newman 알고리즘은 전체 그래프에서 탐색을 시작한다.\n",
    "> - 군집들이 서로 분리되도록, **간선을 순차적으로 제거**한다.\n",
    "> - 어떤 간선을 제거해야 군집들이 분리될까\n",
    "    - 바로 서로 다른 군집을 연결하는 **다리(Bridge)역할의 간선**이다.\n",
    "\n",
    "> - 서로 다른 군집을 연결하는 다리 역할의 간선을 어떻게 찾아낼 수 있을까\n",
    "> - 간선의 **매개 중심성(Betweenness Centrality)**을 사용한다.\n",
    "> - 이는 해당 간선이 **정점 간의 최단 경로에 놓이는 횟수**를 의미한다.\n",
    "    - 정점 $i$로 부터 $j$로의 최단 경로 수를 $\\sigma_{i, j}$라고 하고 그 중 간선 $(x. y)$를 포함한 것을 $\\sigma_{i, j}(x, y)$라고 하자.\n",
    "    - 간선 $(x, y)$의 매개 중심성은 다음 수식으로 계산된다.\n",
    "    - $\\sum_{i < j} \\frac{\\sigma_{i, j} (x, y)}{\\sigma_{i, j}}$\n",
    "> - **매개 중심성**을 통해 서로 다른 군집을 연결하는 **다리 역할의 간선**을 찾아낼 수 있다.\n",
    "\n",
    "> - **`Girvan-Newman 알고리즘`**은 **매개 중심성이 높은 간선을 순차적으로 제거**한다.\n",
    "> - 간선이 제거될 때마다, 매개 중심성을 다시 계산하여 갱신한다.\n",
    "> - 간선이 모두 제거될 때까지 반복합니다\n",
    "> - 간선의 제거 정도에 따라서 **다른 입도(Granularity)의 군집 구조**가 나타난다.\n",
    "\n",
    "> - 간선을 어느 정도 제거하는 것이 가장 적합할까\n",
    "> - 앞서 정의한 **군집성**을 그 기준으로 삼는다.\n",
    "> - 즉, **군집성이 최대가 되는 지점까지 간선을 제거**한다.\n",
    "> - 단, 현재의 연결 요소들을 군집으로 가정하되, 입력 그래프에서 군집성을 계산한다.\n",
    "\n",
    "> - **Girvan-Newman 알고리즘은 다음과 같다.**\n",
    "> - 1) 전체 그래프에서 시작한다.\n",
    "> - 2) **매개 중심성이 높은 순서로 간선을 제거**하면서, 군집성을 변화를 기록한다.\n",
    "> - 3) **군집성이 가장 커지는 상황을 복원**한다.\n",
    "> - 4) 이 때, 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 간주한다.\n",
    "> - 즉, 전체 그래프에서 시작해서 점점 작은 단위를 검색하는 **하향식(Top-Down)** 방법이다.\n",
    "\n",
    "### 3.2 Louvain 알고리즘\n",
    "\n",
    "> - **`Louvain 알고리즘`**은 **대표적인 상향식(Bottom-Up) 군집 탐색 알고리즘**이다.\n",
    "> - Louvain 알고리즘은 개별 정점에서 시작해서 점점 큰 군집을 형성한다.\n",
    "> - **`군집성`을 기준으로 군집을 합친다.**\n",
    "\n",
    "> - Louvain 알고리즘의 동작 과정은 다음과 같다.\n",
    "> - 1) Louvain 알고리즘은 **개별 정점으로 구성된 크기 1의 군집**들로부터 시작한다.\n",
    "> - 2) 각 정점 $u$를 기존 혹은 새로운 군집으로 이동한다.\n",
    "> - 이 때, **군집성이 최대화**되도록 군집을 결정한다.\n",
    "> - 3) 더 이상 **군집성이 증가하지 않을 때까지 2)를 반복**한다.\n",
    "> - 4) 각 **군집을 하나의 정점으로하는 군집 레벨의 그래프**를 얻은 뒤 3)을 수행한다.\n",
    "> - 5) **한 개의 정점이 남을 때까지 4)를 반복**한다.\n",
    "\n",
    "## 4. 중첩이 있는 군집 탐색\n",
    "\n",
    "### 4.1 중첩이 있는 군집 구조\n",
    "\n",
    "> - **실제 그래프의 군집들을 중첩되어 있는 경우가 많다.**\n",
    "> - 예를 들어 소셜 네트워크에서의 개인은 여러 사회적 역할을 수행하고 그 결과 여러 군집에 속하게 된다.\n",
    "\n",
    "> - 앞서 배운 Girvan-Newman 알고리즘, Louvain 알고리즘은 군집 간의 중첩이 없다고 가정한다.\n",
    "> - 그러면 중첩이 있는 군집은 어떻게 찾아낼 수 있을까\n",
    "\n",
    "### 4.2 중첩 군집 모형\n",
    "\n",
    "> - 이를 위해 아래와 같은 **중첩 군집 모형**을 가정한다.\n",
    "> - 1) 각 정점은 여러 개의 군집에 속할 수 있다.\n",
    "> - 2) 각 군집 $A$에 대하여, 같은 군집에 속하는 두 정점은 $P_A$확률로 간선으로 직접 연결된다.\n",
    "> - 3) 두 정점이 여러 군집에 동시에 속할 경우 간선 연결 확률은 독립적이다.\n",
    "    - 예를 들어, 두 정점이 군집 $A$와 $B$에 동시에 속할 경우 두 정점이 간선으로 직접 연결될 확률은 $1-(1-P_A)(1-P_B)$이다.\n",
    "> - 4) 어느 군집에도 함께 속하지 않는 두 정점은 낮은 확률 $\\epsilon$으로 직접 연결된다.\n",
    "\n",
    "> - **중첩 군집 모형이 주어지면, 주어진 `그래프의 확률`을 계산할 수 있다.**\n",
    "> - 그래프의 확률은 다음 확률들의 곱이다.\n",
    "> - 1) 그래프의 각 간선의 두 정점이 (모형에 의해) 직접 연결될 확률\n",
    "> - 2) 그래프에서 직접 연결되지 않은 각 정점 쌍이 (모형에 의해) 직접 연결되지 않을 확률\n",
    "\n",
    "> - **`중첩 군집 탐색`**은 주어진 **그래프의 확률을 최대화**하는 **중첩 군집 모형**을 찾는 과정이다.\n",
    "> - 통계 용어를 빌리면, 최우도 추정치(Maximum Likelihood Estimate)를 찾는 과정이다.\n",
    "\n",
    "### 4.3 완화된 중첩 군집 모형\n",
    "\n",
    "> - **중첩 군집 탐색을 용이하게 하기 위하여 `완화된 중첩 군집 모형`을 사용한다.**\n",
    "> - 완화된 중첩 군집 모형에서는 각 정점이 각 **군집에 속해 있는 정도를 실숫값으로 표현**한다.\n",
    "> - 즉, 기존 모형에서는 각 정점이 각 군집에 속하거나 속하지 않거나 둘 중 하나였는데, 중간 상태를 표현할 수 있게 된 것이다.\n",
    "> - 최적화 관점에서는, 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구(경사하강법 등)를 사용하여 모형을 탐색할 수 있다는 장점이 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
