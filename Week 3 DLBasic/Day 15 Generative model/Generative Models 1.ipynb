{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-trace",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "> - what I can not create I do not understand - Richard Feynman\n",
    "> - What does it mean to learn a **generactive model**?\n",
    "\n",
    "#### Learning Generative Model\n",
    "\n",
    "> - Suppose we are given images of dogs\n",
    "> - We want to learn a probability distribution $p(x)$ such that\n",
    "    - **Generation** : If we sample $x_{new} \\thicksim p(x), x_{new}$  should look like a dog (**sampling**)\n",
    "    - **Density estimator** : $p(x)$ should be high if $x$ looks like a dog, and low otherwise (**anomaly detection**)\n",
    "    - **Unsupervised representation learning** : We should be able to learn what these images have in common, e.g., ears, tail, etc (**feature learning**)\n",
    "    \n",
    "#### Basic Discrete Distributions\n",
    "\n",
    "> #### Bernoulli distribution\n",
    "> - (biased) coin flip\n",
    "> - $D = \\{\\text{Heads, Tails}\\}$\n",
    "> - Specify $P(X = \\text{Heads}) = p$. Then $P(X = \\text{Tails}) = 1 - p$\n",
    "> - Write : $X \\thicksim \\text{Ber}(p)$\n",
    "\n",
    "> #### Categorical distribution\n",
    "> - (biased) m-sided dice\n",
    "> - $D = \\{1,\\dots,m\\}$\n",
    "> - Specify $P(Y = i) = p_i$. such that $\\sum_{i=1}^m p_i = 1$\n",
    "> - Write : $Y \\thicksim \\text{Cat}(p1,\\dots,p_m)$\n",
    "\n",
    "#### Structure Through Independence\n",
    "\n",
    "\n",
    "> - What if $X_1, \\dots, X_n$ independent, then $p(x_1, \\dots, x_n) = p(x_1)p(x_2)\\cdots(x_n)$\n",
    "> - How many possible states? $2^n$\n",
    "> - How many parameters to specify $p(x_1, \\dots, x_n)$? $n$\n",
    "> - $2^n$ entries can be described by just $n$ numbers!\n",
    "> - But this **independence** assumption is too strong to model useful distributions\n",
    "\n",
    "#### Conditional Independence\n",
    "\n",
    "> #### Chain rule\n",
    "> - $p(x_1, \\dots, x_n) = p(x_1)p(x_2|x_1) \\cdots p(x_n|x_1,\\dots,x_{n-1})$\n",
    "\n",
    "> #### Bayes' rule\n",
    "> - $p(x|y) = \\frac{p(x, y)}{p(y)} = \\frac{p(y|x)p(x)}{p(y)}$\n",
    "\n",
    "> #### Conditional independence\n",
    "> - if $x \\bot y|z,$ then $p(x|y,z) = p(x|z)$\n",
    "\n",
    "> - Using the chain rule\n",
    "    - $p(x_1, \\dots, x_n) = p(x_1)p(x_2|x_1) \\cdots p(x_n|x_1,\\dots,x_{n-1})$\n",
    "> - How may parameters?\n",
    "    - $p(x)$ : 1 parameter\n",
    "    - $p(x_2|x_1)$ : 2 parameters $p(x_2|x_1 = 0), p(x_2|x_1 = 1)$\n",
    "    - $p(x_3|x_1, x_2)$ : 4 parameters\n",
    "    - Hence, $1 + 2 + \\cdots + 2^{n-1} = 2^n - 1$, which is the same as before\n",
    "> - Now, suppose $X_{i+1} \\bot X_1,\\dots,X_{i-1} | X_i$ (Markov assumtion), then $p(x_1, \\dots, x_n) = p(x_1)p(x_2|x_1)p(x_3|x_2)\\cdots(x_n|x_{n-1})$\n",
    "> - How many parameters? $2n - 1$\n",
    "> - Hence, by leveraging the Markov assumption, we got exponential reduction on the number of parameters.\n",
    "> - **`Auto-regressive models`** leverage this **conditional independency**\n",
    "\n",
    "#### Auto-regressive models\n",
    "\n",
    "> - We need **an ordering** of all random variables\n",
    "\n",
    "#### NADE\n",
    "\n",
    "> - Neural Autoregressive Density Estimator\n",
    "> - The porbability distribution of $i$-th pixel is  $p(x_i|x_{1:i-1}) = \\sigma(\\alpha_i \\mathbf{h}_i + b_i)$ where $\\mathbf{h}_i = \\sigma(W_{<i}x_{1:i-1} + \\mathbf{c})$\n",
    "\n",
    "> - **`NADE`** is an **explicit** model that can compute the **dencity** of the given inputs\n",
    "> - We can compute the **density** of the given image\n",
    "> - In case of modeling continuous random variables, **a mixture of Gaussian** can be used\n",
    "\n",
    "#### Pixel RNN\n",
    "\n",
    "> - We can also use **RNNs** to define an auto-regressive model\n",
    "> - There are two model architectures in Pixel RNN based on the **ordering** of chain\n",
    "    - Row LSTM\n",
    "    - Diagonal BiLSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
