{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consolidated-saturn",
   "metadata": {},
   "source": [
    "### 1. 두 문장 관계 분류 task 소개\n",
    "\n",
    "#### 1.1 두 문장 관계 분류 task\n",
    "\n",
    "> - 주어진 2개의 문장에 대해, 두 문장의 자연어 추론과 의미론적인 유사성을 측정하는 task\n",
    "\n",
    "#### 1.2 두 문장 관계 분류를 위한 데이터\n",
    "\n",
    "> - **Natural Language Inference** (NLI)\n",
    "    - 언어모델이 자연어의 맥락을 이해할 수 있는지 검증하는 task\n",
    "    - 전체문장(Premise)과 가설문장(Hypothesis)을 Entailment(함의), Contradiction(모순), Neutral(중립)으로 분류\n",
    "    \n",
    "> - **Semantic text pair**\n",
    "    - 두 문장의 의미가 서로 같은 문장인지 검증하는 task\n",
    "    \n",
    "### 2. 두 문장 관계 분류 모델 학습\n",
    "\n",
    "#### 2.1 Information Retrieval Question and Answering (IRQA)\n",
    "\n",
    "> - 기존 chatbot과의 차이점\n",
    "    - **Paraphrase Detection**\n",
    "    \n",
    "> - 1) 학습 데이터 구축\n",
    "    - 하나의 문장에 대한 similar_sents 리스트 생성\n",
    "    - similar_sents 리스트 안에 있는 문장은 유사한 문장\n",
    "    - 전체 sentence를 iteration 하면서 리스트 안에 없지만 유사한 문장 Top-N개의 리스트 생성 (non_similar_sents)\n",
    "    - non_similar_sents 리스트 안에 있는 문장은 유사하지 않은 문장\n",
    "    - **어려운 문제로 학습을 시키면 모델이 어려운 문제를 만났을 때 더 잘 맞힐 수 있다.**\n",
    "    \n",
    "> - 2) 유사도 비교 모델 학습\n",
    "    - 1번의 유사한 문장, 유사하지 않은 문장으로 모델 학습\n",
    "    \n",
    "> - 3) Chatbot\n",
    "    - 모든 sentence를 vector화 시킨다.\n",
    "    - Query vector와 모든 sentence와 유사도 비교\n",
    "    - Top-N개의 문장을 iteration 하면서 **2번에서 학습한 유사한 문장인지 판단**\n",
    "    - 유사한 문장일 경우 해당 Answer 출력 / 아닐 경우 다음 문장 확인\n",
    "    \n",
    "### 찐(?) 피어세션\n",
    "\n",
    "> - (익효)\n",
    "> - Data에 MASK를 씌우고 학습을 해볼 것 \n",
    "> - 종헌님 코드가 괜찮아 보인다.\n",
    "\n",
    "> - (종헌)\n",
    "> - Koelectra일 때 Unknown token을 모두 vocab에 추가할 때는 성능이 올라갔다.\n",
    "> - XLMRobert에서는 좋지 않다...\n",
    "    - accuracy가 멈추는 구간이 많아진다.\n",
    "    - 학습에 방해가 된다고 생각해 쓰지 않는다.\n",
    "> - 다양한 실험 끝에 tokenizer는 건드리지 않는걸로...\n",
    "\n",
    "> - (재희)\n",
    "> - entity 구분 token 추가\n",
    "> - 2.4% 향상\n",
    "> - ```Python\n",
    "    # 추천 방법\n",
    "    ENT1 </s> ENT2 </s> </s> <e1> ENT1 </e1> <e2> ENT2 </e2>\n",
    "    ```\n",
    "\n",
    "> - (익효)\n",
    "> - Embedding layer 실험해보지는 않았지만 피어세션 팀원들부터 나온 결과로는 오르지 않는다.\n",
    "> - 아니였다...\n",
    "> - 첫번째 문장 뒤에 \"앞의 문장에서 a와 b는 어떤 관계야?\"를 넣었을 때 성능이 좋지 않았다.\n",
    "\n",
    "> - (종헌)\n",
    "> - Entity를 앞에 붙여주는 것이 안 붙여주는 것보다 결과적으로 좋다.\n",
    "\n",
    "> - (현규)\n",
    "> - ```Python\n",
    "    이순신 [SEP] 조선 </s> </s> ...\n",
    "    ```\n",
    "> - ```Python\n",
    "    이순신 </s> 조선 </s> </s> ...\n",
    "    ```\n",
    "> - 위에서 아래로 바꾸었을 때 성능이 올라갈거라는 예상을 했지만 극락...\n",
    "> - (익효) Entity 두 개를 연결해주는 영어 단어(SEPERATE)를 넣어주니 올라갔다.\n",
    "> - (재희) 최대한 간결하게 하는 것이 좋을 거 같다.\n",
    "> - ```Python\n",
    "    <sub>이순신</sub>은 <obj>조선</obj>중기 무신\n",
    "    이순신과 조선의 관계는 무엇인가?\n",
    "    ```\n",
    "> - 성능이 올랐다. (3%!!)\n",
    "> - max_length를 150으로 늘렸을 때는 올리고 300은 떨어짐..\n",
    "> - Question Type으로 진행할 예정\n",
    "> - 번역을 사용했을 때 validation은 높았지면 결과로는 별로....\n",
    "> - 학습이 고정되는 문제....가 자주 발생...\n",
    "    - (익효) learing rate를 계속 낮추면서 될때까지.. 또 안되면 SGD 무조건 될 때까지\n",
    "    - (종헌) 스케줄러 X 1e-5를 했을때 괜찮아짐\n",
    "> - Overfitting 된다고 생각해 6 epoch\n",
    "    - (종헌) 5 epoch\n",
    "    - (재희) 5 epoch\n",
    "> - 일반화 성능을 확인하고 그 다음에 ensemble하는 것이 좋다.\n",
    "    - 여러 실험을 해야 되기 때문에\n",
    "    \n",
    "> - (종헌)\n",
    "> - 0.5 더해주는 것보다는 data 확률분포를 바탕으로 더해줘야 겠다.\n",
    "    - (익효) 0이 많이 틀리기 때문에 softmax 값을 취하고 10%를 더해주기 위해 0.5를 추가\n",
    "    - 0.7도 해보고 싶지만 제출 횟수가 너무 아깝다...\n",
    "    - 안올라갈수가 없다.\n",
    "    \n",
    "> - (현규)\n",
    "> - Bucketting\n",
    "> - get groups lenghts?\n",
    "    - 길이 비슷한 text끼리 group화를 시켜 padding을 최소화 시킴\n",
    "    - 처리해야 할 것들이 많다..\n",
    "    \n",
    "> - (재희)\n",
    "> - Embedding layer 줄 수 있는 방법\n",
    "    - R-Bert\n",
    "    - 종헌님도 도전\n",
    "    \n",
    "> - (현규)\n",
    "> - 데이터를 임의로 자르고 순서 바꾸기\n",
    "    - ex) 이순신은 조선 중기의 무신이다.\n",
    "    - ex) 조선 중기의 무신이다. 이순신은"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-kitchen",
   "metadata": {},
   "source": [
    "### 새로 학습한 내용\n",
    "\n",
    "\n",
    "### 시도한 것\n",
    "\n",
    "> - wandb 적용\n",
    "> - Entity 기준으로 양 옆 50만 보는 preprocessing 적용\n",
    "    - train 기준 200을 넘는 데이터가 거의 없다.(2-3개?)\n",
    "> - Ensemble 적용(Hard voting)\n",
    "    - softvoting은 모델 저장이 안 돼 할 수가 없다....\n",
    "\n",
    "### TODO\n",
    "\n",
    "> - Entity에 special token 추가해보기\n",
    "> - 첫번째 문장 변경\n",
    "    - ex) ENT1, ENT2의 관계는?\n",
    "> - 데이터를 임의로 자르고 순서 바꾸기\n",
    "    - ex) 이순신은 조선 중기의 무신이다.\n",
    "    - ex) 조선 중기의 무신이다. 이순신은"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
